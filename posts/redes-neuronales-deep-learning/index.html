<!DOCTYPE html><html lang="es" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Redes neuronales y Deep Learning" /><meta property="og:locale" content="es" /><meta name="description" content="Introducción" /><meta property="og:description" content="Introducción" /><link rel="canonical" href="https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/" /><meta property="og:url" content="https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/" /><meta property="og:site_name" content="Marcos Ruiz" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-10-23T10:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Redes neuronales y Deep Learning" /><meta name="twitter:site" content="@whataweekhuh" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-04-24T14:16:06+02:00","datePublished":"2023-10-23T10:00:00+02:00","description":"Introducción","headline":"Redes neuronales y Deep Learning","mainEntityOfPage":{"@type":"WebPage","@id":"https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/"},"url":"https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/"}</script><title>Redes neuronales y Deep Learning | Marcos Ruiz</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Marcos Ruiz"><meta name="application-name" content="Marcos Ruiz"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" https://avatars.githubusercontent.com/u/7647613?v=4 " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Marcos Ruiz</a></div><div class="site-subtitle font-italic">Trabaja duro para ser vago</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>INICIO</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORÍAS</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>ETIQUETAS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVOS</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>SOBRE MÍ</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/marcosruiz" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['profesor.mruizg','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Inicio </a> </span> <span>Redes neuronales y Deep Learning</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Artículo</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Buscar..."> </span> <span id="search-cancel" >Cancelar</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Redes neuronales y Deep Learning</h1><div class="post-meta text-muted"><div> <em> <a href="https://github.com/marcosruiz">Marcos Ruiz</a> </em></div><div class="d-flex"><div> <span> <em class="timeago" data-ts="1698048000" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-10-23 </em> </span> <span> Actualizado <em class="timeago" data-ts="1713960966" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2024-04-24 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="3706 palabras"> <em>20 minutos</em> lectura</span></div></div></div><div class="post-content"><h2 id="introducción"><span class="mr-2">Introducción</span><a href="#introducción" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><iframe width="560" height="315" src="https://www.youtube.com/embed/xrQ1YH0PnrM?si=0FnJ-LY-pmQ0-XLq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Preguntas sobre el vídeo:</p><ol><li>¿Qué dos tipos de aprendizaje no supervisado nombra en el vídeo?<li>¿En que consiste el aprendizaje semisupervisado?</ol><iframe width="560" height="315" src="https://www.youtube.com/embed/CU24iC3grq8?si=l6X0IN17URaNKdjj" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Preguntas sobre el vídeo:</p><ol><li>¿Por qué no nos vamos de viaje si no tenemos dinero?<li>¿Qué es un perceptrón? ¿Cuáles son sus partes?<li>¿Qué es un perceptrón multicapa?<li>¿Podemos ajustar manualmente los pesos de una neurona? ¿Y el umbral?</ol><iframe width="560" height="315" src="https://www.youtube.com/embed/UNFFLJPW7KQ?si=ANBQi78GomKXqOkg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Preguntas sobre el vídeo:</p><ol><li>¿Esconde la inteligencia artificial estructuras if/else “ocultas”? ¿Por qué?<li>¿Cuántas capas ocultas debe tener la red neuronal de ejemplo del vídeo?<li>¿Cada neurona de la capa de entrada se conecta con cada neurona de la primera capa oculta?<li>¿La red neuronal siempre funciona mejor con más datos de entrenamiento?<li>¿Se puede programar con estructuras if/else el ejemplo del vídeo?</ol><h2 class="section" id="definición-y-esquema-general-de-una-red-neuronal">Definición y esquema general de una red neuronal</h2><h3 class="subsection" id="qué-es-una-neurona">¿Qué es una neurona?</h3><p>Una neurona artificial es una función matemática concebida como un modelo de una neurona biológica. La neurona artificial recibe una o más entradas y las suma para producir una salida. Por lo general, cada entrada se pondera por separado con un peso y la suma se pasa a través de una función no lineal conocida como función de activación.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/neurona.png" alt="Estructura básica de una neurona" data-proofer-ignore> <em>Estructura básica de una neurona</em></p><p class="question">¿Es lo mismo una neurona que un perceptrón?</p><h3 class="subsection" id="qué-es-una-red-neuronal">¿Qué es una red neuronal?</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/MRIv2IwFTPg?si=GB_NvnUb9bQVU_m6" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Preguntas sobre el vídeo:</p><ol><li>¿Es lo mismo una neurona artificial que una función matemática?<li>¿Cuál es la solución para resolver el problema de clasificación del XOR?</ol><iframe width="560" height="315" src="https://www.youtube.com/embed/uwbHOpp9xkc?si=I8f6J5MOt7rs8RLZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>Preguntas sobre el vídeo:</p><ol><li>¿Cuales son los 3 tipos de capas de una red neuronal?<li>¿Qué ocurre cuando sumamos varias líneas rectas entre si?<li>¿Qué funciones de activación nombra en DotCSV en el vídeo?</ol><p>Las redes neuronales artificiales (llamadas simplemente redes neuronales) son sistemas informáticos inspirados en las redes neuronales biológicas que constituyen los cerebros de los animales.</p><p>Una red neuronal se basa en una colección de neuronas artificiales. Cada conexión, como las sinapsis en un cerebro biológico, puede transmitir una señal a otras neuronas. Una neurona artificial recibe señales, luego las procesa y puede enviar señales a las neuronas conectadas a ella. La “señal” en una conexión es un número real, y la salida de cada neurona se calcula mediante alguna función no lineal de la suma de sus entradas. Las redes neuronales artificiales (llamadas simplemente redes neuronales) son sistemas informáticos inspirados en las redes neuronales biológicas que constituyen los cerebros de los animales.</p><p>Una red neuronal se basa en una colección de neuronas artificiales. Cada conexión, como las sinapsis en un cerebro biológico, puede transmitir una señal a otras neuronas. Una neurona artificial recibe señales, luego las procesa y puede enviar señales a las neuronas conectadas a ella. La “señal” en una conexión es un número real, y la salida de cada neurona se calcula mediante alguna función no lineal de la suma de sus entradas.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/redNeuronal.gif" alt="Estructura de una red neuronal" data-proofer-ignore> <em>Estructura de una red neuronal</em></p><p class="question">¿Qué es el bias?</p><h3 class="subsection" id="funciones-de-activación">Funciones de activación</h3><p>La función de activación determina, como su propio nombre indica, el nivel de activación que alcanza cada neurona una vez que ha recibido los impulsos transmitidos. Estas funciones ostentan un rol muy importante en la determinación del poder computacional de la red neuronal.</p><p>La función de activación se encarga de devolver una salida a partir de un valor de entrada, normalmente el conjunto de valores de salida en un rango determinado como <code class="language-plaintext highlighter-rouge">(0,1)</code> o <code class="language-plaintext highlighter-rouge">(-1,1)</code>.</p><p>Se buscan funciones que las derivadas sean simples, para minimizar con ello el coste computacional.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/activationFunctions.png" alt="Funciones de activación" data-proofer-ignore> <em>Funciones de activación</em></p><p>Link muy explicativo sobre los diferentes tipos de funciones de activación: <a href="https://www.diegocalvo.es/funcion-de-activacion-redes-neuronales/">https://www.diegocalvo.es/funcion-de-activacion-redes-neuronales/</a>.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/_0wdproot34?si=U-E-WtjHZmq9xI8c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><h4 class="subsubsection" id="función-de-activación-softmax">Función de activación Softmax</h4><p>En la teoría de la probabilidad, la salida de la función softmax se puede utilizar para representar una distribución categórica, es decir, una distribución de probabilidad sobre K diferentes resultados posibles. Por tanto, la función softmax se utiliza para clasificación multiclase. Podríamos considerar la función softmax como una generalización de la función sigmoid que permite clasificar más de dos clases. La función de activación softmax nos garantiza que todas las probabilidades estimadas son entre 0 y 1 y que suman 1.</p><p>A nivel matemático, softmax usa el valor exponencial de las evidencias calculadas y, luego, las normaliza de modo que sumen uno, formando una distribución de probabilidad.</p>\[\sigma: \mathbb{R}^K \to [0,1]^K\] \[\sigma(z_i) = \frac{e^{z_{i}}}{\sum_{j=1}^K e^{z_{j}}} \ \ \ for\ i=1,2,\dots,K\]<p><img data-src="/assets/img/redes-neuronales-deep-learning/multiClassClassificationWithSoftMaxFunction.png" alt="Ejemplo de la función de activación softmax" data-proofer-ignore> <em>Ejemplo de la función de activación softmax</em></p><h3 class="subsection" id="sobreajuste">Sobreajuste</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/7-6X3DTt3R8?si=oNIBKqKjjwAfyI2c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/ZmLKqZYlYUI?si=tPIzowmxq1uiixnH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/elH6MOFtJJg?si=StWrxYuOonPgNabB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><h3 class="subsection" id="algoritmos-de-redes-neuronales">Algoritmos de redes neuronales</h3><h2 class="section" id="deep-learning">Deep Learning</h2><p>El aprendizaje profundo es un tipo avanzado de aprendizaje automático dentro de las redes neuronales.</p><p>El aprendizaje profundo es un enfoque moderno basado en un modelo conceptual de cómo funciona el cerebro humano. El modelo (también llamado red neuronal) está compuesto por colecciones de neuronas (unidades computacionales muy simples) conectadas entre sí por pesos (representaciones matemáticas de cuánta información se permite que fluya de una neurona a la siguiente). Los pesos de estas conexiones codifican el conocimiento de una red. Estos pesos en los enlaces pueden incrementar o inhibir el estado de activación de las neuronas adyacentes. Del mismo modo, a la salida de la neurona, puede existir una función limitadora o umbral, que modifica el valor resultado o impone un límite que no se debe sobrepasar antes de propagarse a otra neurona. Esta función se conoce como función de activación.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/perceptron.png" alt="Perceptrón" data-proofer-ignore> <em>Perceptrón</em></p><p>El proceso de entrenamiento implica encontrar valores para cada peso.</p><p>En la actualidad existen muchos tipos diferentes de redes neuronales para modelar diferentes tipos de problemas o procesar diferentes tipos de datos.</p><p>Una red neuronal profunda posee tres o más capas de redes neuronales internas (hidden) y tiene nodos neuronales anidados tal que por cada pregunta que responde conduce a un conjunto de preguntas relacionadas.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/mlVsDl.png" alt="Machine Learning vs Deep Learning" data-proofer-ignore> <em>Machine Learning vs Deep Learning</em></p><p><img data-src="/assets/img/redes-neuronales-deep-learning/deepLearningKingGeorge.png" alt="Machine Learning vs Deep Learning" data-proofer-ignore> <em>Machine Learning vs Deep Learning</em></p><p><img data-src="/assets/img/redes-neuronales-deep-learning/redNeuronalPartidoDeFutbol.png" alt="Estimación del resultado de un partido de fútbol" data-proofer-ignore> <em>Estimación del resultado de un partido de fútbol</em></p><iframe width="560" height="315" src="https://www.youtube.com/embed/FVozZVUNOOA?si=JHtRk2_s1OW8uRf1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/eNIqz_noix8?si=xVDZkGRsR931dGSZ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/M5QHwkkHgAA?si=IyrnSWhUVVE_-iMt" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <details class="card mb-2"> <summary class="card-header question">¿Es lo mismo deep learning que aprendizaje profundo?</summary><div class="card-body"><p>Si</p></div></details><h3 class="subsection" id="inconvenientes-del-deep-learning">Inconvenientes del Deep Learning</h3><ul><li>El aprendizaje profundo “suele” requerir un conjunto de datos de gran tamaño para el entrenamiento.<li>Los conjuntos de entrenamiento para el aprendizaje profundo se componen “a veces” de millones de puntos de datos.<li>Una vez que se ha entrenado una red neuronal profunda con estos conjuntos de datos de gran tamaño, puede controlar más ambigüedad que una red superficial.</ul><h3 class="subsection" id="topologías-de-redes-neuronales-profundas">Topologías de Redes Neuronales Profundas</h3><p>Existen muchas topologías de las redes neuronales:</p><ul><li><strong>Red Neuronal de Avance - Feed Forward Neural Network (FFNN)</strong><li>Red de Base Radial - Radial Basis Network (RBN)<li>Red de Alimentación Directa Profunda - Deep Feed Forward (DFF)<li><strong>Red con Memoria a Corto y Largo Plazo - Long / Short Term Memory (LSTM)</strong><li>Red de Unidades Periódicas Cerradas - Gated Recurrent Unit (GRU)<li>Red Neuronal de Codificador Automático - Auto Encoder (AE)<li>Red de Autoencoder Variacional - Variational Auto Encoder (VAE)<li>Red de Codificador Automático de Eliminación de Ruido - Denoising Auto Encoder (DAE)<li>Red de Autoencoder Dispersa - Sparse Auto Encoder (SAE)<li>Red de Cadenas de Markov - Markov Chain (MC)<li>Red Hopfield - Hopfield Network (HN)<li>Red de Máquinas Boltzmann - Boltzmann Machine (BM)<li>Red Restringida de Máquinas de Boltzmann - Restricted Boltzmann Machine (RBM)<li>Red de Creencias Profundas - Deep Belief Network (DBN)<li><strong>Red Neuronal Convolucional - Convolutional Neural Network (CNN) o Deep Convolutional Network (DCN)</strong><li>Red Neuronal Deconvolucional - Deconvolutional Network (DN)<li>Red de Gráficos Inversa Convolucional Profunda - Deep Convolutional Inverse Graphics - Network (DCIGN)<li><strong>Red Generativa de Adversarios - Generative Adversarial Network (GAN)</strong><li>Máquina de Estado Líquido - Liquid State Machine (LSM)<li>Red de Máquinas de Aprendizaje Extremo - Extreme Learning Machine (ELM)<li>Red de Estado de Eco - Echo State Network (ESN)<li>Red Residual Profunda - Deep Residual Network (DRN)<li>Red de Kohonen - Kohoner Network (KN)<li>Máquina de Vector Soporte - Support Vector Machine (SVM)<li>Máquina Neuronal de Turing - Neural Turing Machine (NTM)</ul><p>Pero las más relevantes son:</p><ol><li>Feed Forward Neural Network (FFNN)<li>Convolutional Neural Network (CNN) o Deep Convolutional Network (DCN)<li>Recurrent Neural Network (RNN) o Long / Short Term Memory (LSTM)<li>Generative Adversarial Network (GAN)<li>Transformer Neural Networks</ol><h4 class="subsubsection" id="feed-forward-neural-network-ffnn">Feed Forward Neural Network (FFNN)</h4><p>La forma más sencilla de estructurar una red neuronal. En Feed Forward Neural Network (FFNN) o red prealimentada, donde todas las neuronas de una capa se encuentran conectadas con todas las neuronas de la capa anterior. Cada conexión puede tener una fuerza o un peso diferente. En esta red, la información se mueve en una sola dirección, hacia adelante, desde los nodos de entrada, a través de los nodos ocultos y hacia los nodos de salida. No hay ciclos ni bucles en la red.</p><p>Cuando todas las neuronas de una capa están conectadas con todas las neuronas de la capa anterior, la capa se denomina completamente/densamente conectada.</p><h4 class="subsubsection" id="convolutional-neural-network-cnn-o-dcn">Convolutional Neural Network (CNN o DCN)</h4><iframe width="560" height="315" src="https://www.youtube.com/embed/V8j1oENVz00?si=FxvcjOkicNFkhv64" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/ysqpl6w6Wzg?si=Gvc7SsHqcez37bN8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/4sWhhQwHqug?si=mJ_zGyRr9614UjMT" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><ul><li>Las redes neuronales convolucionales (CNN) representan filtros anidados sobre datos organizados en cuadrículas. Son, con diferencia, el tipo de modelo más utilizado al procesar imágenes.<li>Similares a las Densamente Conectadas.<li>El modelo de redes neuronales convolucionales (CNN) se puede aplicar a tareas de reconocimiento visual.<li>La arquitectura de una CNN está diseñada para aprovechar la estructura de matriz de los datos.<li>Jerarquía de representaciones con creciente nivel de abstracción.<li>Cada etapa es un tipo de transformación de característica entrenable. Por ejemplo, una primera capa convolucional aprende elementos básicos como aristas, y una segunda capa convolucional aprende patrones compuestos de elementos básicos aprendidos en la capa anterior. Y así sucesivamente en cada cada hasta ir aprendiendo patrones muy complejos.</ul><p><img data-src="/assets/img/redes-neuronales-deep-learning/cnn.png" alt="Combinación de capas con diferentes tipos de redes neuronales convolucionales" data-proofer-ignore> <em>Combinación de capas con diferentes tipos de redes neuronales convolucionales</em></p><h5 class="subsubsection" id="capa-de-convolución-convolutional-layer">Capa de convolución (Convolutional layer)</h5><p>La diferencia fundamental entre una capa densamente conectada y una convolucional es que la capa densa aprende patrones globales en su espacio global de entrada, mientras que la capa convolucional aprende patrones locales dentro de la imagen en pequeñas ventanas de dos dimensiones.</p><p>Tomemos como referencia el caso del MNIST, dónde como entrada de nuestra red neuronal podemos pensar en un espacio de neuronas de dos dimensiones 28×28 (height=28, width=28, depth=1). Una primera capa de neuronas ocultas conectadas a las neuronas de la capa de entrada que hemos comentado realizarán las operaciones convolucionales que acabamos de describir. Pero no se conectan todas las neuronas de entrada con todas las neuronas de este primer nivel de neuronas ocultas, sino que solo se hace por pequeñas zonas localizadas del espacio de las neuronas de entrada que almacenan los píxeles de la imagen.</p><p>Si pensamos en una ventana del tamaño de 5×5, iremos recorriendo toda la capa de 28×28 de entrada que contiene la imagen. Esta ventana se va deslizando a lo largo de toda la capa de neuronas. Por cada posición de la ventana hay una neurona en la capa oculta que procesa esta información.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDeConvolucion.png" alt="Ventana de neuronas de la capa de entrada conectadas a neurona de la capa oculta convolucional" data-proofer-ignore> <em>Ventana de neuronas de la capa de entrada conectadas a neurona de la capa oculta convolucional</em></p><p>Visualmente, empezamos con la ventana en la esquina arriba-izquierda de la imagen, y esto le da la información necesaria a la primera neurona de la capa oculta. Después, deslizamos la ventana una posición hacia la derecha para “conectar” las 5×5 neuronas de la capa de entrada incluidas en esta ventana con la segunda neurona de la capa oculta. Y así, sucesivamente, vamos recorriendo todo el espacio de la capa de entrada, de izquierda a derecha y de arriba abajo.</p><p>Observemos que si tenemos una entrada de 28×28 píxeles y una ventana de 5×5 esto nos define un espacio de 24×24 neuronas en la primera capa del oculta, debido a que solo podemos mover la ventana 23 neuronas hacia la derecha y 23 hacia abajo antes de chocar con el lado derecho (o inferior) de la imagen de entrada.</p><p>En nuestro caso de estudio, y siguiendo el formalismo ya presentado previamente, para “conectar” cada neurona de la capa oculta con las 25 neuronas que le corresponden de la capa de entrada usaremos un valor de sesgo b y una matriz de pesos W de tamaño 5×5 que llamaremos filtro (o kernel/filter en inglés).</p><p>En la siguiente imagen, vemos otro ejemplo partiendo de una capa de entrada de 49 neuronas (imagen de 7x7) y un filtro con ventana de 3x3, generará una capa oculta resultante de 25 neuronas (matriz de 5x5) con un padding de relleno a ceros alrededor del margen de la imagen (mejora el resultado del barrido que se realiza en la ventana que se va deslizando)</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDeConvolucion2.png" alt="imgDescription" data-proofer-ignore> <em>Capa convolucional con ventana de 3x3</em></p><p>Es muy importante tener en cuenta que en las redes convolucionales se usa el mismo filtro (la misma matriz W de pesos y el mismo sesgo b) para todas las neuronas de la capa oculta.</p><p>Pero un filtro definido por una matriz W y un sesgo b solo permiten detectar una característica concreta en una imagen; por tanto, para poder realizar el reconocimiento de imágenes se propone usar varios filtros a la vez, uno para cada característica que queramos detectar. En el siguiente ejemplo, vemos que se aplican 32 filtros, donde cada filtro recordemos que se define con una matriz W de pesos compartida de 5×5 y un sesgo b.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDeConvolucion3.png" alt="Capa oculta convolucional con 32 filtros" data-proofer-ignore> <em>Capa oculta convolucional con 32 filtros</em></p><h5 class="subsubsection" id="capa-de-pooling-pooling-layer">Capa de pooling (Pooling layer)</h5><p>Además de las capas convolucionales que acabamos de describir, las redes neuronales convolucionales acompañan a la capa de convolución con unas capas de pooling, que suelen ser aplicadas inmediatamente después de las capas convolucionales. Su función es reducir progresivamente el tamaño espacial de la representación para reducir la cantidad de parámetros y computación en la red. La capa de agrupación opera en cada mapa de características de forma independiente.</p><p>Hay varias maneras de condensar la información, pero una habitual, y que usaremos en nuestro ejemplo, es la conocida como max-pooling, . En el siguiente ejemplo, vemos que se define una ventana de entrada de 2x2 y se queda con el valor máximo de los existentes en la ventana. De esta forma, dividimos por 4 el tamaño de la salida de la capa de pooling, quedando una imagen de 12×12.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDePooling.png" alt="Capa de pooling con ventana de 2x2" data-proofer-ignore> <em>Capa de pooling con ventana de 2x2</em></p><p>En la siguiente captura tenemos una captura de una imagen 7x7 donde se le aplica una ventana 2x2 con un stride (longitud del paso de avance) de 2 en lugar de 1 y por tanto obtenemos un mapa de caracteres de 4x4</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDePooling2.png" alt="Capa de pooling con ventana 2x2 con stride de 2" data-proofer-ignore> <em>Capa de pooling con ventana 2x2 con stride de 2</em></p><p class="question">¿Qué es el stride?</p><p>En la siguiente imagen, vemos gráficamente el resultado de combinar la convolución con pooling:</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/capaDePooling3.png" alt="Combinación de capa de convolución con capa de pooling" data-proofer-ignore> <em>Combinación de capa de convolución con capa de pooling</em></p><p class="question">¿Se pueden combinar las capas de convolución y capas de pooling?</p><h4 class="subsubsection" id="recurrent-neural-network-rnn-o-long--short-term-memory-lstm">Recurrent Neural Network (RNN) o Long / Short Term Memory (LSTM)</h4><p>Las redes neuronales recurrentes (RNN) y los tipos de modelos de memoria a corto plazo a largo plazo (LSTM) están estructurados para representar de manera efectiva los bucles for en la computación tradicional, recolectando estados mientras se itera sobre algún objeto. Por tanto, en este tipo de redes la información puede fluir en cualquier dirección. Se pueden utilizar para procesar secuencias de datos.</p><p>Limitación con Feed Forward Neural Networks (y CNN):</p><ul><li>No diseñadas para datos secuenciales.<li>Dimensión fija de entradas.<li>No modela la memoria.</ul><p>Las redes neuronales recurrentes permiten:</p><ul><li>Para mapear predicciones en secuencias.<li>Esto crea un estado interno de la red que le permite exhibir relaciones temporales dinámicas.<li>Aplicaciones: subtítulos de imágenes, análisis de sentimientos, respuesta a preguntas, reconocimiento de voz, series temporales, generación de música, traducción automática, vehículos autónomos, …</ul><h4 class="subsubsection" id="transformer-neural-networks">Transformer Neural Networks</h4><p>Un reemplazo más moderno para los RNN/LSTM, la arquitectura del transformador permite el entrenamiento sobre conjuntos de datos más grandes que involucran secuencias de datos.</p><iframe width="560" height="315" src="https://www.youtube.com/embed/aL-EmKuB078?si=HL_VPl0QrvTlituH" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/xi94v_jl26U?si=xwnAImUsvwRliusm" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><h4 class="subsubsection" id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)</h4><details class="card mb-2"> <summary class="card-header question">¿Qué es Generative AI?</summary><div class="card-body"><p>La IA generativa es uno de los mayores avances recientes en IA debido a su capacidad para crear nuevas cosas. Hasta hace poco, la mayoría de las aplicaciones de aprendizaje automático funcionaban con modelos discriminativos.</p><p>Un modelo discriminativo tiene como objetivo responder la pregunta: “Si estoy mirando algunos datos, ¿cómo puedo clasificar mejor estos datos o predecir un valor?” Por ejemplo, podríamos usar modelos discriminativos para detectar si una cámara apunta a un gato. Mientras entrenamos este modelo sobre una colección de imágenes (algunas de las cuales contienen gatos y otras que no), esperamos que el modelo encuentre patrones en las imágenes que ayuden a hacer esta predicción.</p><p>Un modelo generativo tiene como objetivo responder a la pregunta: “¿He visto datos como este antes?” En nuestro ejemplo de clasificación de imágenes, aún podríamos usar un modelo generativo al enmarcar el problema en términos de si una imagen con la etiqueta “gato” es más similar a los datos que ha visto antes que una imagen con la etiqueta “sin gato”.</p><p>Sin embargo, los modelos generativos se pueden utilizar para respaldar un segundo caso de uso. Los patrones aprendidos en modelos generativos se pueden utilizar para crear nuevos ejemplos de datos que se parecen a los datos que se vieron antes.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/cat.png" alt="Algoritmos discriminativos vs algoritmos generativos" data-proofer-ignore> <em>Algoritmos discriminativos vs algoritmos generativos</em></p></div></details><p>Las redes generativas adversarias (GAN) son un formato de modelo de aprendizaje automático que implica enfrentar dos redes entre sí para generar contenido nuevo. El algoritmo de entrenamiento alterna entre entrenar una red de generador (responsable de producir nuevos datos) y una red discriminadora (responsable de medir qué tan cerca los datos de la red del generador representan el conjunto de datos de entrenamiento).</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/gan.png" alt="Ejemplo GAN" data-proofer-ignore> <em>Ejemplo GAN</em></p><details class="card mb-2"> <summary class="card-header question">¿Cómo funcionan los filtros de FaceApp?</summary><div class="card-body"><p>Leer <a href="https://mastersofmedia.hum.uva.nl/blog/2017/09/24/neural-networks-the-technology-behind-faceapp/">https://mastersofmedia.hum.uva.nl/blog/2017/09/24/neural-networks-the-technology-behind-faceapp/</a>.</p></div></details><p>Documental sobre Machine Learning y Entrenamiento Humano: <a href="https://www.documaniatv.com/social/trabajadores-fantasma-video_bd817bfb9.html">https://www.documaniatv.com/social/trabajadores-fantasma-video_bd817bfb9.html</a>.</p><h2 class="section" id="fases-del-entrenamiento-de-una-red-neuronal-profunda">Fases del entrenamiento de una Red Neuronal Profunda</h2><p>Descarga los ejemplos: <a href="/assets/img/redes-neuronales-deep-learning/demoKeras1.ipynb">demoKeras1.ipynb</a>, <a href="/assets/img/redes-neuronales-deep-learning/demoKeras2.ipynb">demoKeras2.ipnyb</a></p><p>Etapas para crear una RN densamente conectada:</p><p><strong>Etapa 1:</strong></p><p>Creación del modelo y definición de cada una de las capas.</p><ul><li><code class="language-plaintext highlighter-rouge">model = new Sequential()</code><li><code class="language-plaintext highlighter-rouge">model.add(Dense(&lt;número de neuronas&gt;, activation=&lt;función de activación (‘sigmoid’, ‘softmax’, ‘relu’...)&gt;)</code></ul><p><strong>Etapa 2:</strong></p><p>Configuración del proceso de aprendizaje: método <code class="language-plaintext highlighter-rouge">compile</code>:</p><ul><li>función de coste (<code class="language-plaintext highlighter-rouge">loss function</code>): evalúa el grado de error entre las salidas calculadas y las salidas deseadas de los datos de entrenamiento. El objetivo está en reducir dicho valor en cada iteración.<li>optimizador (<code class="language-plaintext highlighter-rouge">optimizer</code>): es la manera que tenemos de indicar los detalles del algoritmo de optimización que permite a la red neuronal calcular los pesos de los parámetros durante el entrenamiento a partir de los datos de entrada y de la función de coste definida.<li>métrica (<code class="language-plaintext highlighter-rouge">metrics</code>): es la que usaremos para monitorizar el proceso de aprendizaje y prueba de nuestra red neuronal. Si indicamos <code class="language-plaintext highlighter-rouge">accuracy</code> solo tendremos en cuenta la fracción de datos que son correctamente clasificados, es decir, la proporción entre las predicciones correctas que ha hecho el modelo del total de predicciones.</ul><p><strong>Etapa 3:</strong></p><p>Entrenamiento con los datos de training: método <code class="language-plaintext highlighter-rouge">fit</code>:</p><ul><li><code class="language-plaintext highlighter-rouge">epochs</code>: número de veces que usaremos todos los datos en el proceso de aprendizaje.<li><code class="language-plaintext highlighter-rouge">verbose</code>: permite ver el avance del entrenamiento así como una estimación de cuánto tarda cada época.</ul><p><strong>Etapa 4:</strong></p><p>Evaluación con los datos de testing: método <code class="language-plaintext highlighter-rouge">evaluate</code>:</p><p>Para redes neuronales que clasifiquen, volveremos a referirnos a la matriz de confusión:</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/metodoEvaluate.png" alt="Método evaluate" data-proofer-ignore> <em>Método evaluate</em></p><ul><li>TP: cantidad de positivos que fueron clasificados correctamente como positivos por el modelo.<li>TN: cantidad de negativos que fueron clasificados correctamente como negativos por el modelo.<li>FN: cantidad de positivos que fueron clasificados incorrectamente como negativos.<li><p>FP: cantidad de negativos que fueron clasificados incorrectamente como positivos.</p><li>Si utilizamos la precisión (accuracy), conoceremos la proporción entre las predicciones correctas que ha hecho el modelo del total de predicciones, ya que <code class="language-plaintext highlighter-rouge">Presicion=(TP+TN)/(TP+TN+FP+FN)</code>.<li>Si utilizamos el recall: sabremos como de bien el modelo evita los falsos negativos, ya que Recall = TP/(TP+FN)</ul><p><strong>Etapa 5:</strong></p><p>Generación de predicciones: método <code class="language-plaintext highlighter-rouge">predict</code>.</p><h3 class="subsection" id="función-de-pérdida-loss-function">Función de pérdida (Loss function)</h3><p>En las redes neuronales, las funciones de pérdida ayudan a optimizar el rendimiento del modelo. Suelen utilizarse para medir alguna penalización en la que incurre el modelo en sus predicciones, como la desviación de la predicción con respecto a la etiqueta de verdad. Las funciones de pérdida suelen ser diferenciables en todo su dominio (pero se permite que el gradiente sea indefinido sólo para puntos muy concretos, como x = 0, que básicamente se ignora en la práctica). En el bucle de entrenamiento, se diferencian con respecto a los parámetros, y estos gradientes se utilizan para sus pasos de retropropagación y descenso de gradiente para optimizar su modelo en el conjunto de entrenamiento.</p><p>Las funciones de pérdida también son ligeramente diferentes de las métricas. Mientras que las funciones de pérdida pueden indicarnos el rendimiento de nuestro modelo, puede que no sean de interés directo o fácilmente explicables por los humanos. Aquí es donde entran en juego las métricas. Métricas como la precisión son mucho más útiles para que los humanos entiendan el rendimiento de una red neuronal, aunque no sean buenas opciones para las funciones de pérdida, ya que pueden no ser diferenciables.</p><p>Existen diferentes métricas del error según trabajamos con problemas de regresión o clasificación.</p><p>Métricas para problemas de regresión y RRNN:</p><ul><li>The Mean Absolute Error (Error absoluto medio): $EAM = \frac{1}{n} \sum_{i=1}^{n} abs(y_i - \hat{y}_i)$<li>Mean Squared Error (Error cuadrático medio): $ECM = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$<li>Raíz Cuadrada del Error Cuadrático Medio $RCECM = \frac{1}{n} \sum_{i=1}^{n} \sqrt{(y_i - \hat{y}_i)^2}$<li>Logarithmic Loss: $LogLoss = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]$<li>Accuracy</ul><p>Métricas para regresiones logísticas cuando tenemos dos clasificaciones:</p><ul><li>Logistic Loss<li>Binary Cross Entropy (Entropía cruzada binaria)</ul><p>Métricas para problemas de clasificación:</p><ul><li>Categorical Cross Entropy (Entropía Cruzada Categórica): Esta función necesita que la salida de la red neuronal sean tantos nodos como categorías hay.<li>Sparse Categorical Cross Entropy (Entropía Cruzada Categórica Dispersa)</ul><h3 class="subsection" id="descenso-del-gradiente">Descenso del gradiente</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/A6FiCDoz8_4?si=ZNN_y9eIB5PAuMSR" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/-_A_AAxqzCg?si=Lfn42fSem5v9IhqF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe><p>El descenso de gradiente es un algoritmo de optimización de primer orden.</p><p>Encuentre un mínimo local de una función usando el descenso de gradiente, uno da pasos proporcionales al negativo del gradiente de la función en el punto actual.</p><p><img data-src="/assets/img/redes-neuronales-deep-learning/descensoDelGradiente.png" alt="Ilustración del descenso de gradiente en una serie de conjuntos de niveles" data-proofer-ignore> <em>Ilustración del descenso de gradiente en una serie de conjuntos de niveles</em></p><p>La función de pérdida toma las predicciones de la red y las compara con los targets objetivo. De esta forma, calcula una puntuación de distancia, capturando cómo de bien funciona la red neuronal.</p><p>El truco fundamental en el aprendizaje profundo es utilizar esta puntuación como una señal de retroalimentación para ajustar un poco el valor de los pesos, en una dirección que reducirá la puntuación de pérdida para el lote actual de ejemplos (gradiente negativo).</p><p>El gradiente ($\nabla J (\theta)$) se calcula por retropropagación.</p><p>Calcula el gradiente de una función de pérdida con respecto a todos los pesos en la red (regla de la cadena) y lo usa para actualizar los pesos para minimizar la función de pérdida.</p><h3 class="subsection" id="backpropagation">Backpropagation</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/Ilg3gGewQ5U?si=AT2hCYX4ViAHm0I-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/tIeHLnjs5U8?si=hI4EdSs64cQ1CpJE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/eNIqz_noix8?si=YpYuPWoAqvRxxo8F" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe> <iframe width="560" height="315" src="https://www.youtube.com/embed/M5QHwkkHgAA?si=awU9XdJNmIlCY5Yc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe><h2 id="bibliografía"><span class="mr-2">Bibliografía</span><a href="#bibliografía" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li><a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code">https://github.com/Avik-Jain/100-Days-Of-ML-Code</a><li><a href="https://es.wikipedia.org/wiki/Red_generativa_adversativa">https://es.wikipedia.org/wiki/Red_generativa_adversativa</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/inteligencia-artificial-y-big-data/'>Inteligencia Artificial y Big Data</a>, <a href='/categories/sistemas-de-aprendizaje-autom%C3%A1tico/'>Sistemas de aprendizaje automático</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/inteligencia-artificial-y-big-data/" class="post-tag no-text-decoration" >inteligencia artificial y big data</a> <a href="/tags/sistemas-de-aprendizaje-autom%C3%A1tico/" class="post-tag no-text-decoration" >sistemas de aprendizaje automático</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> Este artículo está licenciado bajo <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> por el autor.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Compartir</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Redes neuronales y Deep Learning - Marcos Ruiz&amp;url=https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Redes neuronales y Deep Learning - Marcos Ruiz&amp;u=https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://marcosruiz.github.io/posts/redes-neuronales-deep-learning/&amp;text=Redes neuronales y Deep Learning - Marcos Ruiz" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copiar link" data-title-succeed="Link copiado satisfactoriamente!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recientemente actualizado</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/tutorial-moodle-docker/">Tutorial: Instalar Moodle con Docker</a><li><a href="/posts/tutorial-nextcloud/">Tutorial: Monta tu propio Google Drive con NextCloud</a><li><a href="/posts/guias-estilo/">Guías de estilo</a><li><a href="/posts/callbacks-javascript/">Callbacks en JavaScript</a><li><a href="/posts/propagacion-eventos-javascript/">Propagación de eventos en JavaScript</a></ul></div><div id="access-tags"><div class="panel-heading">Etiquetas populares</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/smr/">smr</a> <a class="post-tag" href="/tags/daw/">daw</a> <a class="post-tag" href="/tags/desarrollo-de-aplicaciones-web/">desarrollo de aplicaciones web</a> <a class="post-tag" href="/tags/teor%C3%ADa/">teoría</a> <a class="post-tag" href="/tags/ciclo-superior/">ciclo superior</a> <a class="post-tag" href="/tags/fp/">fp</a> <a class="post-tag" href="/tags/modulo/">modulo</a> <a class="post-tag" href="/tags/pr%C3%A1ctica/">práctica</a> <a class="post-tag" href="/tags/formaci%C3%B3n-profesional/">formación profesional</a> <a class="post-tag" href="/tags/seguridad-inform%C3%A1tica/">seguridad informática</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Índice</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Otros artículos</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/tarea-clustering/"><div class="card-body"> <em class="timeago small" data-ts="1709539200" > 2024-03-04 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Tarea: Clustering</h3><div class="text-muted small"><p> Entrega y presentación La entrega será en formato PDF. Leer Entrega y presentación de tareas. Calificación La tarea se calificará con una nota de 0 a 10. Duración: - horas Actividades Descarg...</p></div></div></a></div><div class="card"> <a href="/posts/sistemas-aprendizaje-automatico-23-24/"><div class="card-body"> <em class="timeago small" data-ts="1694073600" > 2023-09-07 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Sistemas de Aprendizaje Automático 23 24</h3><div class="text-muted small"><p> Evaluación 1 UD1 - Justificación y antecedentes del Aprendizaje Automático UD2 - Tipos de algoritmos en relación con el aprendizaje automático Aprendizaje Supervisado Aprend...</p></div></div></a></div><div class="card"> <a href="/posts/tarea-aplicacion-modelos-probabilisticos/"><div class="card-body"> <em class="timeago small" data-ts="1697356800" > 2023-10-15 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Tarea: Aplicación de modelos probabilísticos</h3><div class="text-muted small"><p> Entrega y presentación La entrega será en formato PDF. Leer Entrega y presentación de tareas. Calificación La tarea se calificará como apto o no apto. Actividades Max ya ha estudiado algunas t...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/algoritmos-aprendizaje-automatico/" class="btn btn-outline-primary" prompt="Más viejo"><p>Algoritmos para el aprendizaje automático</p></a> <a href="/posts/tutorial-anaconda/" class="btn btn-outline-primary" prompt="Más nuevo"><p>Tutorial: Entornos de desarrollo para Aprendizaje Automático</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "marcosruiz/marcosruiz.github.io", "data-repo-id": "R_kgDOGm1dzA", "data-category": "General", "data-category-id": "DIC_kwDOGm1dzM4CAjhb", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "es", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://github.com/marcosruiz">Marcos Ruiz</a>. <span data-toggle="tooltip" data-placement="top" title="Excepto donde si indique lo contrario, los artículos de este blog están licenciados bajo Creative Commons Attribution 4.0 International (CC BY 4.0) Licenciado por el autor.">Algunos derechos reservados.</span></p></div><div class="footer-right"><p class="mb-0"> Desarrollado por <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> con el tema <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> .</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Etiquetas populares</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/smr/">smr</a> <a class="post-tag" href="/tags/daw/">daw</a> <a class="post-tag" href="/tags/desarrollo-de-aplicaciones-web/">desarrollo de aplicaciones web</a> <a class="post-tag" href="/tags/teor%C3%ADa/">teoría</a> <a class="post-tag" href="/tags/ciclo-superior/">ciclo superior</a> <a class="post-tag" href="/tags/fp/">fp</a> <a class="post-tag" href="/tags/modulo/">modulo</a> <a class="post-tag" href="/tags/pr%C3%A1ctica/">práctica</a> <a class="post-tag" href="/tags/formaci%C3%B3n-profesional/">formación profesional</a> <a class="post-tag" href="/tags/seguridad-inform%C3%A1tica/">seguridad informática</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! Resultado no encontrado.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/es.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-GS5HW4NZ8V"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-GS5HW4NZ8V'); }); </script>
